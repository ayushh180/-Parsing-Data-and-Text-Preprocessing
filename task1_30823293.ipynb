{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT5196 Assignment 1\n",
    "\n",
    "## Task 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Student name: $ \\text {Ayush Sharma} $\n",
    "\n",
    " Due date: 13 Sept 2020\n",
    "\n",
    "Environment: Python 3.6.0 and Anaconda 4.3.0 (64-bit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Library used:\n",
    "* re: This library is used to work on the document for pattern matching using regular expression\n",
    "* os: os library is used to parse between directory and the files in it to load them for reading the data\n",
    "* langid: langid is a python library the help identify the langague passed into the string and identify the language of the text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.) INTRODUCTION: \n",
    "This assignment works on text processing and parsing between mupltiples files. Looking at the task it focuses on analyzing textual data which includes extracting data which can be in form of semi-structured data as well. Provides by the examiner we are given data of 2020 tweets bases on COVID-19/ CoronaVirus. \n",
    "The task is to extract the data and transform the data into the XML format with the following\n",
    "elements:\n",
    "1. id: is a 19-digit number.\n",
    "2. text: is the actual tweet.\n",
    "3. Created_at: is the date and time that the tweet was created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.) Importing Library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import re\n",
    "import os\n",
    "import langid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.) Loading Data and Storing it:\n",
    "First work is to load the data from the folder that has more then 2000+ text files that contains the tweet, date, id I have contain the directory in a list and parse on it to read each file and work on it. It is loaded in a variable named `data`.\n",
    "- each tweet have a date id and tweet text this can be in any order\n",
    "- I have iterated the list of files and opened them one by one and appended it to a single string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 53.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "file_list=[]\n",
    "path = '30823293_Task1/'\n",
    "for root, dirs, files in os.walk(path):\n",
    "    file_list = files\n",
    "data=str()        \n",
    "for i in file_list:\n",
    "    textdata=open(path+i,'r',encoding='UTF-8')\n",
    "    data=data+textdata.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.) Processing on the Data\n",
    "In this step we will read the whole text data and analyse it according to the required items that are need and will work on understaning the data after loading the tweet data in the `data ` variable I printed it and understood the form of data and after that I understood that it is a semi-structed data. \n",
    "\n",
    "- to make the data in a better format and work on it in a better way I decided to create a list\n",
    "- using the 'split' function of a list type data we have converted the `text string` into a list from `{` because each tweet begined at `{`.\n",
    "- Created empty lists to append the required data of date, tweet, and id.\n",
    "- I have applied 3 regex to extract the date, tweet Id, and the tweet text\n",
    "### used RegEx:\n",
    "\n",
    "- Tweet Text: `(?:(?:\"text\":\"(.*?)(?:(?:\"})|(?:\",\"created_at\")|(?:\",\"id\"))))` which extracts the text by finding the pattern\n",
    "- Tweet ID : `(?:\"id\":\"(.*?)\")`\n",
    "- Tweet Date:`((?:20[1-2][0-9])-(?:0[0-9]|[1][0-2])-(?:[0-2][0-9]|[3][0-1]))` look for the pattern of a specified date only\n",
    "- these three Regex have returned me three list and now I have matched each list and checked if there are tweets against each id \n",
    "- then I have created a tuple with first element as the date and followed by id and text of tweet \n",
    "- Replaced all the special characters with text and changed the encoding of different characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Splitting data at {and creating list for each tweet\n",
    "splitted_tweets=data.split(\"{\")\n",
    "# Empty list for tweet\n",
    "list_tup=[]\n",
    "# empty lisr of ids\n",
    "list_of_ids=[]\n",
    "for tweet in splitted_tweets:\n",
    "    # Date regEx\n",
    "    date_list=re.findall(\"((?:20[1-2][0-9])-(?:0[0-9]|[1][0-2])-(?:[0-2][0-9]|[3][0-1]))\",tweet)\n",
    "    #Id RegEx\n",
    "    id_list=re.findall('(?:\"id\":\"(.*?)\")',tweet)\n",
    "    # List RegEx\n",
    "    text_list=re.findall('(?:(?:\"text\":\"(.*?)(?:(?:\"})|(?:\",\"created_at\")|(?:\",\"id\"))))',tweet)\n",
    "    #checking if there are all the elemeent of the tweet present\n",
    "    if(len(date_list)!=0 and len(id_list)!=0 and len(text_list)!=0):\n",
    "        if(id_list[0] not in list_of_ids):\n",
    "            list_of_ids.append(id_list[0])        \n",
    "            list_tup.append((date_list[0],id_list[0],(eval('\"'+text_list[0]+'\"').encode('utf-16', 'surrogatepass')\\\n",
    "                                                      .decode('utf-16')).replace(\"<\",\"&lt;\").replace(\">\",\"&gt;\")\\\n",
    "                             .replace(\"&\",\"&amp;\").replace(\"'\",\"&apos;\").replace('\"',\"&quot;\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.) Filtering English Tweets:\n",
    "\n",
    "In this step I have Filtered all the tweets that were not of english language as required by the specifications all the tweets are removed using the `langid classifier` function from the langid libarary which we imported previously for this purpose Finally I have appended all the english tweet to a list of tuples that have the Date, Id, tweet text.\n",
    "\n",
    "Following that I have converted it into the dictionary that has the date as the key to which we need our tweets in i.e for one date all the tweets that has that date. now we have date as key and a List of tuples where each tuple has a tweet id and text at 0 and 1 position.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12min 7s\n"
     ]
    }
   ],
   "source": [
    "#creating tuple from the above tuple and running langid classifier \n",
    "# That Classifies the data only on en language and keep it\n",
    "tup2=list_tup\n",
    "tt=[]\n",
    "for i in tup2:\n",
    "    if langid.classify(i[2])[0]=='en':\n",
    "        tt.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 111 ms\n"
     ]
    }
   ],
   "source": [
    "# Creating dictionary as date as key and value as list of items with id and text\n",
    "dict_1=dict() \n",
    "  \n",
    "for date,ids,text  in tt: \n",
    "    dict_1.setdefault(date, []).append((ids,text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  6.) Creating XML:\n",
    "\n",
    "Now using the Dictionary I have made a string which is in the `XML` format by iterating over the dictiary and extracting its key for date and values using the value which are in a list of tuple format and accesing it using the index .\n",
    "appending each value within the string I have created the text format for the for the XML and write the file using the write function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 49min 25s\n"
     ]
    }
   ],
   "source": [
    "# Formating the string\n",
    "strin='<?xml version=\"1.0\" encoding=\"UTF-8\"?>'+'\\n'+'<data>'\n",
    "for i,j in dict_1.items():\n",
    "    strin=strin+'\\n'+'<tweets date='+'\"'+i+'\"'+'>'+'\\n'\n",
    "    for j in dict_1[i]:\n",
    "        strin=strin+'<tweet id='+'\"' +(j[0])+'\"'+'>'+j[1]+'</tweet>'+'\\n'\n",
    "strin=strin+'</tweets>'+'\\n'+'</data>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 154 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Writing the file\n",
    "finalxml = open(\"30823293.xml\", \"w\",encoding='UTF-8')\n",
    "finalxml.write(strin)\n",
    "finalxml.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "After the completion of the task I was able to create an XML file that has all the tweet date, tweets text, tweet id in the required format.\n",
    "From this Task I learnt how to handle unprocessed semi- structured data by exploring it and analysing the pattern using regular expression  library that help me identify the pattern of the data and how to extract them with help of regular expression, dictionary in python, and langid package to filter out non english tweets and repeted tweets I was able to exttract and store the data in a structred format and generate the XML.\n",
    "This Task has helped me understand how regEx works and how to extract data and apply exploration on it to get desired format.\n",
    "\n",
    "\n",
    "Thank You"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
